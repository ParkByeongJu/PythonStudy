{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e8ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6129fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata = fetch_20newsgroups(subset = 'train') # 'train'을 기재하면 훈련 데이터만 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a4a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1534f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 샘플의 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c823fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제의 개수 : 20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4711ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4740b6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c329d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc48133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(newsdata.data, columns = ['email'])\n",
    "data['target'] = pd.Series(newsdata.target)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2bdb8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 132.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d93e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3374be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플의 수 : 11314\n",
      "중복을 제외한 주제의 수 : 20\n"
     ]
    }
   ],
   "source": [
    "print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))\n",
    "print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc70d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f974815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('target').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0edc3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "train_email = data['email']\n",
    "train_label = data['target']\n",
    "test_email = newsdata_test.data\n",
    "test_label = newsdata_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c533ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ecf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, mode): # 전처리 함수\n",
    "    tokenizer = Tokenizer(num_words = vocab_size) # vocab_size 개수만큼의 단어만 사용한다.\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    X_train = tokenizer.texts_to_matrix(train_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    X_test = tokenizer.texts_to_matrix(test_data, mode=mode) # 샘플 수 × vocab_size 크기의 행렬 생성\n",
    "    return X_train, X_test, tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac90c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary') # binary 모드로 변환\n",
    "y_train = to_categorical(train_label, num_classes) # 원-핫 인코딩\n",
    "y_test = to_categorical(test_label, num_classes) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6460bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f73afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1번 단어 : the\n",
      "빈도수 상위 9999번 단어 : mic\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))\n",
    "print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96e93653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vocab_size,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=100, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed041050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 2.2845 - accuracy: 0.3376 - val_loss: 0.9521 - val_accuracy: 0.8322\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.8688 - accuracy: 0.7665 - val_loss: 0.4495 - val_accuracy: 0.8878\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8874 - val_loss: 0.3492 - val_accuracy: 0.9019\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2602 - accuracy: 0.9355 - val_loss: 0.3064 - val_accuracy: 0.9081\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9640 - val_loss: 0.2982 - val_accuracy: 0.9108\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9721 - val_loss: 0.3022 - val_accuracy: 0.9099\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9815 - val_loss: 0.2973 - val_accuracy: 0.9178\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9853 - val_loss: 0.2990 - val_accuracy: 0.9187\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9881 - val_loss: 0.2912 - val_accuracy: 0.9125\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9897 - val_loss: 0.2964 - val_accuracy: 0.9196\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9894 - val_loss: 0.3081 - val_accuracy: 0.9205\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9917 - val_loss: 0.3076 - val_accuracy: 0.9108\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9933 - val_loss: 0.3166 - val_accuracy: 0.9205\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9929 - val_loss: 0.3248 - val_accuracy: 0.9196\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9939 - val_loss: 0.3262 - val_accuracy: 0.9178\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9945 - val_loss: 0.3441 - val_accuracy: 0.9152\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9955 - val_loss: 0.3409 - val_accuracy: 0.9196\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9944 - val_loss: 0.3374 - val_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.3678 - val_accuracy: 0.9178\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.3532 - val_accuracy: 0.9161\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.3728 - val_accuracy: 0.9117\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.3556 - val_accuracy: 0.9143\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.3865 - val_accuracy: 0.9125\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9952 - val_loss: 0.3813 - val_accuracy: 0.9099\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9936 - val_loss: 0.3976 - val_accuracy: 0.9072\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.3834 - val_accuracy: 0.9117\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9960 - val_loss: 0.3846 - val_accuracy: 0.9143\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.4071 - val_accuracy: 0.9134\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.4059 - val_accuracy: 0.9134\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.4009 - val_accuracy: 0.9170\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.4138 - val_accuracy: 0.9143\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.3975 - val_accuracy: 0.9143\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9961 - val_loss: 0.4131 - val_accuracy: 0.9108\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9962 - val_loss: 0.4120 - val_accuracy: 0.9125\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.3994 - val_accuracy: 0.9152\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.3929 - val_accuracy: 0.9161\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.4084 - val_accuracy: 0.9125\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.4057 - val_accuracy: 0.9090\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.4131 - val_accuracy: 0.9108\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.3951 - val_accuracy: 0.9134\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.3878 - val_accuracy: 0.9143\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.3975 - val_accuracy: 0.9161\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3882 - val_accuracy: 0.9125\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.3912 - val_accuracy: 0.9161\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.4582 - val_accuracy: 0.9125\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.4143 - val_accuracy: 0.9178\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9968 - val_loss: 0.4084 - val_accuracy: 0.9187\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.4008 - val_accuracy: 0.9134\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.4115 - val_accuracy: 0.9170\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.4325 - val_accuracy: 0.9170\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.4086 - val_accuracy: 0.9205\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.4505 - val_accuracy: 0.9170\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 0.4752 - val_accuracy: 0.9108\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.4748 - val_accuracy: 0.9187\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.4575 - val_accuracy: 0.9196\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.4649 - val_accuracy: 0.9152\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.4750 - val_accuracy: 0.9187\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4797 - val_accuracy: 0.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.4412 - val_accuracy: 0.9178\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.4644 - val_accuracy: 0.9205\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.4798 - val_accuracy: 0.9108\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.4683 - val_accuracy: 0.9152\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.4620 - val_accuracy: 0.9223\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4551 - val_accuracy: 0.9152\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.4783 - val_accuracy: 0.9143\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.4692 - val_accuracy: 0.9152\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.4740 - val_accuracy: 0.9170\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9977 - val_loss: 0.4964 - val_accuracy: 0.9152\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4783 - val_accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.5012 - val_accuracy: 0.9196\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.5139 - val_accuracy: 0.9152\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.5001 - val_accuracy: 0.9178\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.4856 - val_accuracy: 0.9187\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.4946 - val_accuracy: 0.9143\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.4927 - val_accuracy: 0.9178\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9965 - val_loss: 0.4835 - val_accuracy: 0.9134\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.4714 - val_accuracy: 0.9081\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.4800 - val_accuracy: 0.9170\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.4594 - val_accuracy: 0.9170\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4634 - val_accuracy: 0.9152\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.4822 - val_accuracy: 0.9196\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.4980 - val_accuracy: 0.9170\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 0.4787 - val_accuracy: 0.9125\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.4902 - val_accuracy: 0.9214\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.4712 - val_accuracy: 0.9231\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.4806 - val_accuracy: 0.9170\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.4933 - val_accuracy: 0.9152\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.5111 - val_accuracy: 0.9161\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.4738 - val_accuracy: 0.9178\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.5234 - val_accuracy: 0.9196\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9946 - val_loss: 0.5710 - val_accuracy: 0.9143\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9947 - val_loss: 0.5038 - val_accuracy: 0.9072\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5500 - val_accuracy: 0.9108\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.5357 - val_accuracy: 0.9152\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.4995 - val_accuracy: 0.9178\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.4855 - val_accuracy: 0.9161\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.4901 - val_accuracy: 0.9187\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.5755 - val_accuracy: 0.9099\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.5068 - val_accuracy: 0.9152\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.5432 - val_accuracy: 0.9134\n",
      "binary 모드의 테스트 정확도: 0.8124004006385803\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 2.8272 - accuracy: 0.2294 - val_loss: 1.6510 - val_accuracy: 0.7155\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.4892 - accuracy: 0.6247 - val_loss: 0.7112 - val_accuracy: 0.8587\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.7916 - accuracy: 0.7982 - val_loss: 0.5077 - val_accuracy: 0.8799\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.8736 - val_loss: 0.4487 - val_accuracy: 0.8825\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.9205 - val_loss: 0.3828 - val_accuracy: 0.8993\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2818 - accuracy: 0.9357 - val_loss: 0.4070 - val_accuracy: 0.8940\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.9525 - val_loss: 0.3648 - val_accuracy: 0.8993\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9581 - val_loss: 0.3734 - val_accuracy: 0.8984\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9671 - val_loss: 0.3604 - val_accuracy: 0.9072\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9673 - val_loss: 0.4029 - val_accuracy: 0.8905\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9765 - val_loss: 0.3986 - val_accuracy: 0.9019\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9838 - val_loss: 0.4362 - val_accuracy: 0.9055\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9844 - val_loss: 0.4206 - val_accuracy: 0.9002\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9868 - val_loss: 0.4144 - val_accuracy: 0.8993\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9852 - val_loss: 0.4201 - val_accuracy: 0.8922\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9841 - val_loss: 0.4235 - val_accuracy: 0.8940\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9807 - val_loss: 0.4857 - val_accuracy: 0.8949\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9861 - val_loss: 0.4011 - val_accuracy: 0.8993\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9770 - val_loss: 0.4233 - val_accuracy: 0.9072\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9839 - val_loss: 0.4159 - val_accuracy: 0.8966\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9821 - val_loss: 0.4226 - val_accuracy: 0.8984\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9866 - val_loss: 0.4599 - val_accuracy: 0.8984\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9830 - val_loss: 0.4392 - val_accuracy: 0.8949\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9914 - val_loss: 0.4335 - val_accuracy: 0.8958\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9810 - val_loss: 0.5110 - val_accuracy: 0.8949\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.4686 - val_accuracy: 0.8975\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9923 - val_loss: 0.4732 - val_accuracy: 0.8975\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9902 - val_loss: 0.5348 - val_accuracy: 0.8984\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9863 - val_loss: 0.5270 - val_accuracy: 0.8940\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9912 - val_loss: 0.5291 - val_accuracy: 0.8896\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9892 - val_loss: 0.5426 - val_accuracy: 0.8913\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9890 - val_loss: 0.5306 - val_accuracy: 0.8993\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9902 - val_loss: 0.5559 - val_accuracy: 0.8958\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9921 - val_loss: 0.5605 - val_accuracy: 0.8913\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9921 - val_loss: 0.5461 - val_accuracy: 0.9046\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9923 - val_loss: 0.5476 - val_accuracy: 0.8975\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9909 - val_loss: 0.5203 - val_accuracy: 0.9002\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9929 - val_loss: 0.5307 - val_accuracy: 0.9055\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9949 - val_loss: 0.5065 - val_accuracy: 0.9064\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9946 - val_loss: 0.5023 - val_accuracy: 0.9037\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.5083 - val_accuracy: 0.9046\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9939 - val_loss: 0.5554 - val_accuracy: 0.8949\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9916 - val_loss: 0.5545 - val_accuracy: 0.9002\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9930 - val_loss: 0.5395 - val_accuracy: 0.9037\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9935 - val_loss: 0.5892 - val_accuracy: 0.9028\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9942 - val_loss: 0.5403 - val_accuracy: 0.8966\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 0.5854 - val_accuracy: 0.8913\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9966 - val_loss: 0.5965 - val_accuracy: 0.8993\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.5719 - val_accuracy: 0.9055\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9960 - val_loss: 0.6038 - val_accuracy: 0.9019\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9954 - val_loss: 0.5776 - val_accuracy: 0.9055\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9943 - val_loss: 0.5942 - val_accuracy: 0.8958\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.5872 - val_accuracy: 0.9046\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.5794 - val_accuracy: 0.8984\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9934 - val_loss: 0.7062 - val_accuracy: 0.8878\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9922 - val_loss: 0.7142 - val_accuracy: 0.8825\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9888 - val_loss: 0.6714 - val_accuracy: 0.8852\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9851 - val_loss: 0.6739 - val_accuracy: 0.8878\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9875 - val_loss: 0.6628 - val_accuracy: 0.8931\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9937 - val_loss: 0.6782 - val_accuracy: 0.8940\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.6877 - val_accuracy: 0.8949\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9934 - val_loss: 0.6632 - val_accuracy: 0.8922\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9929 - val_loss: 0.7012 - val_accuracy: 0.8896\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.7354 - val_accuracy: 0.8869\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9910 - val_loss: 0.6721 - val_accuracy: 0.8922\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9945 - val_loss: 0.6394 - val_accuracy: 0.8940\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.6942 - val_accuracy: 0.8931\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.6714 - val_accuracy: 0.9011\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9962 - val_loss: 0.6598 - val_accuracy: 0.8949\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.6750 - val_accuracy: 0.8913\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.6492 - val_accuracy: 0.8993\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.6317 - val_accuracy: 0.9002\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.6292 - val_accuracy: 0.9037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.6428 - val_accuracy: 0.9019\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.6661 - val_accuracy: 0.8993\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9961 - val_loss: 0.7301 - val_accuracy: 0.8913\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9942 - val_loss: 0.6944 - val_accuracy: 0.8949\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9924 - val_loss: 0.6873 - val_accuracy: 0.8949\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9907 - val_loss: 0.7635 - val_accuracy: 0.8878\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9920 - val_loss: 0.6571 - val_accuracy: 0.8913\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9930 - val_loss: 0.6666 - val_accuracy: 0.9028\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9935 - val_loss: 0.7264 - val_accuracy: 0.8966\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.7144 - val_accuracy: 0.8993\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 0.7192 - val_accuracy: 0.8966\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.6898 - val_accuracy: 0.9002\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.6710 - val_accuracy: 0.9011\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.6795 - val_accuracy: 0.9046\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.6717 - val_accuracy: 0.9019\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.6759 - val_accuracy: 0.8949\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.6677 - val_accuracy: 0.8975\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.6841 - val_accuracy: 0.8984\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9962 - val_loss: 0.7335 - val_accuracy: 0.8940\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9968 - val_loss: 0.7180 - val_accuracy: 0.8966\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.7361 - val_accuracy: 0.8993\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 0.7298 - val_accuracy: 0.8958\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.7763 - val_accuracy: 0.9019\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.7685 - val_accuracy: 0.9011\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 0.7205 - val_accuracy: 0.8993\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.6465 - val_accuracy: 0.9002\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.7057 - val_accuracy: 0.8958\n",
      "count 모드의 테스트 정확도: 0.8227562308311462\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 2.2338 - accuracy: 0.3583 - val_loss: 0.7755 - val_accuracy: 0.8516\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.8453 - accuracy: 0.7731 - val_loss: 0.4158 - val_accuracy: 0.8993\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8843 - val_loss: 0.3417 - val_accuracy: 0.9046\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.9268 - val_loss: 0.3313 - val_accuracy: 0.9125\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9512 - val_loss: 0.3372 - val_accuracy: 0.9117\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9603 - val_loss: 0.3131 - val_accuracy: 0.9223\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9713 - val_loss: 0.3098 - val_accuracy: 0.9214\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9745 - val_loss: 0.3341 - val_accuracy: 0.9249\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9814 - val_loss: 0.3202 - val_accuracy: 0.9205\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9819 - val_loss: 0.3316 - val_accuracy: 0.9205\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9835 - val_loss: 0.3466 - val_accuracy: 0.9187\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9851 - val_loss: 0.3725 - val_accuracy: 0.9223\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9827 - val_loss: 0.3902 - val_accuracy: 0.9125\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9878 - val_loss: 0.3950 - val_accuracy: 0.9152\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9864 - val_loss: 0.3822 - val_accuracy: 0.9223\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9842 - val_loss: 0.3783 - val_accuracy: 0.9196\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9873 - val_loss: 0.4108 - val_accuracy: 0.9099\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9869 - val_loss: 0.3831 - val_accuracy: 0.9152\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9903 - val_loss: 0.3748 - val_accuracy: 0.9205\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9899 - val_loss: 0.3904 - val_accuracy: 0.9258\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9895 - val_loss: 0.3951 - val_accuracy: 0.9231\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9909 - val_loss: 0.4347 - val_accuracy: 0.9117\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9862 - val_loss: 0.4220 - val_accuracy: 0.9161\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9918 - val_loss: 0.4235 - val_accuracy: 0.9178\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9895 - val_loss: 0.4852 - val_accuracy: 0.9117\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9854 - val_loss: 0.4150 - val_accuracy: 0.9205\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9924 - val_loss: 0.4229 - val_accuracy: 0.9196\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9888 - val_loss: 0.4780 - val_accuracy: 0.9134\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9917 - val_loss: 0.4680 - val_accuracy: 0.9134\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9895 - val_loss: 0.4876 - val_accuracy: 0.9152\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9908 - val_loss: 0.4723 - val_accuracy: 0.9152\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9936 - val_loss: 0.5068 - val_accuracy: 0.9081\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9911 - val_loss: 0.5332 - val_accuracy: 0.9143\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9886 - val_loss: 0.5121 - val_accuracy: 0.9117\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9890 - val_loss: 0.4844 - val_accuracy: 0.9090\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9917 - val_loss: 0.4646 - val_accuracy: 0.9161\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.4687 - val_accuracy: 0.9125\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9922 - val_loss: 0.5220 - val_accuracy: 0.9152\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9922 - val_loss: 0.5652 - val_accuracy: 0.9152\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9938 - val_loss: 0.4922 - val_accuracy: 0.9178\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.5310 - val_accuracy: 0.9187\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.5321 - val_accuracy: 0.9152\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9934 - val_loss: 0.5298 - val_accuracy: 0.9161\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.5096 - val_accuracy: 0.9196\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.5196 - val_accuracy: 0.9125\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9945 - val_loss: 0.5352 - val_accuracy: 0.9134\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.5303 - val_accuracy: 0.9125\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9954 - val_loss: 0.5463 - val_accuracy: 0.9152\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9955 - val_loss: 0.5152 - val_accuracy: 0.9108\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9930 - val_loss: 0.5291 - val_accuracy: 0.9143\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9948 - val_loss: 0.5479 - val_accuracy: 0.9117\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9951 - val_loss: 0.5495 - val_accuracy: 0.9108\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9954 - val_loss: 0.5888 - val_accuracy: 0.9011\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9949 - val_loss: 0.5367 - val_accuracy: 0.9081\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9942 - val_loss: 0.5416 - val_accuracy: 0.9055\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.5232 - val_accuracy: 0.9081\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9945 - val_loss: 0.4986 - val_accuracy: 0.9081\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9954 - val_loss: 0.5512 - val_accuracy: 0.9081\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.5693 - val_accuracy: 0.9134\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 0.5817 - val_accuracy: 0.9108\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5815 - val_accuracy: 0.9134\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9956 - val_loss: 0.5906 - val_accuracy: 0.9081\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.5987 - val_accuracy: 0.9125\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9949 - val_loss: 0.5728 - val_accuracy: 0.9108\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.5562 - val_accuracy: 0.9046\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.5253 - val_accuracy: 0.9099\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9936 - val_loss: 0.5167 - val_accuracy: 0.9134\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9949 - val_loss: 0.5345 - val_accuracy: 0.9081\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 0.5479 - val_accuracy: 0.9117\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9953 - val_loss: 0.5622 - val_accuracy: 0.9072\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9937 - val_loss: 0.5715 - val_accuracy: 0.9072\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.5695 - val_accuracy: 0.9108\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9954 - val_loss: 0.5619 - val_accuracy: 0.9117\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.5518 - val_accuracy: 0.9081\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.5591 - val_accuracy: 0.9143\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9958 - val_loss: 0.6373 - val_accuracy: 0.9178\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.5845 - val_accuracy: 0.9108\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9961 - val_loss: 0.5751 - val_accuracy: 0.9125\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9949 - val_loss: 0.6648 - val_accuracy: 0.9090\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9923 - val_loss: 0.6052 - val_accuracy: 0.9134\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.5948 - val_accuracy: 0.9178\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 0.5835 - val_accuracy: 0.9178\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9936 - val_loss: 0.5907 - val_accuracy: 0.9152\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9953 - val_loss: 0.6149 - val_accuracy: 0.9152\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9947 - val_loss: 0.6382 - val_accuracy: 0.9170\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9945 - val_loss: 0.6122 - val_accuracy: 0.9187\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9949 - val_loss: 0.5922 - val_accuracy: 0.9178\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9952 - val_loss: 0.6196 - val_accuracy: 0.9099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9957 - val_loss: 0.6260 - val_accuracy: 0.9161\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9965 - val_loss: 0.6425 - val_accuracy: 0.9223\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.6130 - val_accuracy: 0.9196\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.6568 - val_accuracy: 0.9178\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.6656 - val_accuracy: 0.9134\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.6606 - val_accuracy: 0.9161\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9963 - val_loss: 0.6371 - val_accuracy: 0.9134\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.6697 - val_accuracy: 0.9170\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9958 - val_loss: 0.6508 - val_accuracy: 0.9152\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.6670 - val_accuracy: 0.9178\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.6819 - val_accuracy: 0.9161\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.6716 - val_accuracy: 0.9170\n",
      "tfidf 모드의 테스트 정확도: 0.8248804807662964\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 2.9796 - accuracy: 0.0878 - val_loss: 2.9333 - val_accuracy: 0.1943\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.7427 - accuracy: 0.1967 - val_loss: 2.4159 - val_accuracy: 0.3790\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 2.1797 - accuracy: 0.3193 - val_loss: 1.8649 - val_accuracy: 0.5857\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.7339 - accuracy: 0.4553 - val_loss: 1.4689 - val_accuracy: 0.6440\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.3750 - accuracy: 0.5778 - val_loss: 1.1599 - val_accuracy: 0.7173\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.0905 - accuracy: 0.6680 - val_loss: 0.9425 - val_accuracy: 0.7880\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.8848 - accuracy: 0.7441 - val_loss: 0.7923 - val_accuracy: 0.8145\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.7226 - accuracy: 0.7962 - val_loss: 0.6829 - val_accuracy: 0.8260\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.8353 - val_loss: 0.6032 - val_accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.8646 - val_loss: 0.5492 - val_accuracy: 0.8489\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8885 - val_loss: 0.5113 - val_accuracy: 0.8516\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.9105 - val_loss: 0.4750 - val_accuracy: 0.8595\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.9226 - val_loss: 0.4491 - val_accuracy: 0.8657\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.9313 - val_loss: 0.4337 - val_accuracy: 0.8754\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9428 - val_loss: 0.4189 - val_accuracy: 0.8746\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9524 - val_loss: 0.4090 - val_accuracy: 0.8746\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1757 - accuracy: 0.9584 - val_loss: 0.3988 - val_accuracy: 0.8852\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1579 - accuracy: 0.9646 - val_loss: 0.4008 - val_accuracy: 0.8869\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9681 - val_loss: 0.3872 - val_accuracy: 0.8896\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1247 - accuracy: 0.9722 - val_loss: 0.3916 - val_accuracy: 0.8887\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9775 - val_loss: 0.3836 - val_accuracy: 0.8913\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9788 - val_loss: 0.3859 - val_accuracy: 0.8896\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9810 - val_loss: 0.3816 - val_accuracy: 0.8913\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9842 - val_loss: 0.3827 - val_accuracy: 0.8958\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9862 - val_loss: 0.3877 - val_accuracy: 0.8949\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9861 - val_loss: 0.3839 - val_accuracy: 0.8966\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9881 - val_loss: 0.3918 - val_accuracy: 0.8931\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9892 - val_loss: 0.3985 - val_accuracy: 0.8905\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9922 - val_loss: 0.4037 - val_accuracy: 0.8949\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9917 - val_loss: 0.3952 - val_accuracy: 0.8984\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9914 - val_loss: 0.4003 - val_accuracy: 0.8975\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9932 - val_loss: 0.4023 - val_accuracy: 0.8949\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9939 - val_loss: 0.3992 - val_accuracy: 0.8958\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9942 - val_loss: 0.4128 - val_accuracy: 0.8975\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9952 - val_loss: 0.4129 - val_accuracy: 0.9002\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9949 - val_loss: 0.4154 - val_accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9946 - val_loss: 0.4104 - val_accuracy: 0.9011\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9956 - val_loss: 0.4152 - val_accuracy: 0.8958\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9954 - val_loss: 0.4240 - val_accuracy: 0.9011\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9954 - val_loss: 0.4242 - val_accuracy: 0.8931\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9953 - val_loss: 0.4325 - val_accuracy: 0.9011\n",
      "Epoch 42/100\n",
      "62/80 [======================>.......] - ETA: 0s - loss: 0.0219 - accuracy: 0.9970"
     ]
    }
   ],
   "source": [
    "modes = ['binary', 'count', 'tfidf', 'freq'] # 4개의 모드를 리스트에 저장.\n",
    "\n",
    "for mode in modes: # 4개의 모드에 대해서 각각 아래의 작업을 반복한다.\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode) # 모드에 따라서 데이터를 전처리\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test) # 모델을 훈련하고 평가.\n",
    "    print(mode+' 모드의 테스트 정확도:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027aa907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowPy37",
   "language": "python",
   "name": "tensorflowpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
